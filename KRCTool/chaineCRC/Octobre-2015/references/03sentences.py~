#!/usr/bin/env python
# -*- coding: utf-8 -*-
##########################################################
### Autor name : 		Firas HMIDA		##
### Date de cr√©ation :		07-07-2014		##
### Date de modification : 	23-09-2014		##
### Contenu : 			CRC-Collocations	##
##########################################################

import re
import os
import sys
import xlrd
import time
import nltk
import xlwt
import pickle
import itertools
import subprocess
from math import *
from nltk.collocations import *
from operator import itemgetter
from nltk.corpus import stopwords
from nltk.probability import FreqDist
from nltk.metrics import BigramAssocMeasures
from nltk.tokenize.regexp import RegexpTokenizer
from nltk import word_tokenize, wordpunct_tokenize
from nltk.collocations import BigramCollocationFinder


linesFR = list(set(open('../corpus/vulcanoPOS.txt').read().strip().split('.	SENT	.')))
linesEN = list(set(open('../corpus/vulcanoEN-POS.txt').read().strip().split('.	SENT	.')))

stop_wordsFR = open('../stopW/StopWords.txt').read().strip().split('\n')
stop_wordsEN = open('../stopW/StopWordsEN.txt').read().strip().split('\n')


from operator import itemgetter

out = open('ALLSent.txt','w')

for sentence in linesEN :
	sentence = sentence.lower()
	
        lemmSentence =' '.join([line.split('\t')[2] for line in [l.strip() 
                                            for l in sentence.strip().split('\n')
                                            if len(sentence.strip()) != 0]])
        notLemmSentence =' '.join([line.split('\t')[0] for line in [l.strip() 
                                        for l in sentence.strip().split('\n') 
                                       if len(sentence.strip()) != 0]])
	
	out.write(notLemmSentence+'\n')
